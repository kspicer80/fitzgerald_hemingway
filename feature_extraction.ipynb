{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from helper_functions import load_data\n",
    "\n",
    "# Load the text data from multiple files\n",
    "text_data_list, labels = load_data('data')\n",
    "\n",
    "# Combine the text data into a single list\n",
    "text_data = np.concatenate(text_data_list)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('svd', TruncatedSVD(n_components=2)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "text_data_transformed = pipeline.fit_transform(text_data)\n",
    "# Fit the pipeline to the text data\n",
    "pipeline.fit(text_data, labels)\n",
    "\n",
    "# Retrieve the feature names from the TfidfVectorizer\n",
    "vectorizer = pipeline.named_steps['vectorizer']\n",
    "features = vectorizer.get_feature_names()\n",
    "text_data_transformed = vectorizer.transform(text_data)\n",
    "num_features = text_data_transformed.shape[1]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "text_data_train, text_data_test, labels_train, labels_test = train_test_split(\n",
    "    text_data_transformed, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit the pipeline to the training data and predict the test labels\n",
    "pipeline.fit(text_data_train, labels_train)\n",
    "predictions = pipeline.predict(text_data_test)\n",
    "\n",
    "# Print the classification report and ROC-AUC score\n",
    "print(classification_report(labels_test, predictions))\n",
    "print(\"ROC-AUC:\", roc_auc_score(labels_test, predictions))\n",
    "\n",
    "# Plot the feature importances\n",
    "classifier = pipeline.named_steps['classifier']\n",
    "importances = classifier.feature_importances_\n",
    "plt.bar(range(importances.shape[0]), importances)\n",
    "plt.xlabel(\"feature index\")\n",
    "plt.ylabel(\"feature importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4159a6653fa75438f66a7bfc0596de9be5c1734cbef8b4e22353e9d3f86b82c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
