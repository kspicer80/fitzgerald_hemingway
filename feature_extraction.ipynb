{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: hemingway_bell_tolls.txt\n",
      "Processing file: hemingway_sun_also.txt\n",
      "Processing file: hemingway_in_our_time.txt\n",
      "Processing file: hemingway_green_hills_africa.txt\n",
      "Processing file: hemingway_three_stories_ten_poems.txt\n",
      "Processing file: hemingway_across_the_river.txt\n",
      "Processing file: hemingway_winner_take_nothing.txt\n",
      "Processing file: hemingway_old_man.txt\n",
      "Processing file: hemingway_farewell.txt\n",
      "Processing file: hemingway_men_without_women.txt\n",
      "Processing file: fitzgerald_flappers_and_philosophers.txt\n",
      "Processing file: fitzgerald_tender_is.txt\n",
      "Processing file: fitzgerald_bablyon_revisited.txt\n",
      "Processing file: fitzgerald_gatsby.txt\n",
      "Processing file: fitzgerald_beautiful_and_damned.txt\n",
      "Processing file: fitzgerald_the_vegtable.txt\n",
      "Processing file: fitzgerald_tales_jazz_age.txt\n",
      "Processing file: fitzgerald_this_side.txt\n",
      "Processing file: fitzgerald_all_the_sad.txt\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate((sentence_counts, word_counts, average_word_lengths, average_sentence_lengths), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m text_data, labels \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m text_data_features \u001b[39m=\u001b[39m calculate_features(text_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m text_data_features_sparse \u001b[39m=\u001b[39m csr_matrix(text_data_features)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m text_data_train, text_data_test, labels_train, labels_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     text_data_features, labels, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb Cell 1\u001b[0m in \u001b[0;36mcalculate_features\u001b[0;34m(text_data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     average_word_lengths\u001b[39m.\u001b[39mappend(average_word_length)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     average_sentence_lengths\u001b[39m.\u001b[39mappend(average_sentence_length)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/spicy.kev/Documents/github/fitzgerald_hemingway/feature_extraction.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mconcatenate((sentence_counts, word_counts, average_word_lengths, average_sentence_lengths), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "from helper_functions import load_data\n",
    "from scipy.sparse import csr_matrix\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def calculate_features(text_data):\n",
    "    sentence_counts = []\n",
    "    word_counts = []\n",
    "    average_word_lengths = []\n",
    "    average_sentence_lengths = []\n",
    "    \n",
    "    for text in text_data:\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        sentence_count = len([sent for sent in doc.sents])\n",
    "        word_count = len([token for token in doc])\n",
    "        \n",
    "        average_word_length = sum(len(token) for token in doc) / word_count\n",
    "        average_sentence_length = word_count / sentence_count\n",
    "        \n",
    "        sentence_counts.append(sentence_count)\n",
    "        word_counts.append(word_count)\n",
    "        average_word_lengths.append(average_word_length)\n",
    "        average_sentence_lengths.append(average_sentence_length)\n",
    "    \n",
    "    return np.concatenate((sentence_counts, word_counts, average_word_lengths, average_sentence_lengths), axis=1)\n",
    "\n",
    "text_data, labels = load_data('data')\n",
    "text_data_features = calculate_features(text_data)\n",
    "text_data_features_sparse = csr_matrix(text_data_features)\n",
    "\n",
    "text_data_train, text_data_test, labels_train, labels_test = train_test_split(\n",
    "    text_data_features, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('svd', TruncatedSVD(n_components=2)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(text_data_train, labels_train)\n",
    "\n",
    "score = pipeline.score(text_data_test, labels_test)\n",
    "print(\"Test accuracy:\", score)\n",
    "\n",
    "predictions = pipeline.predict(text_data_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "print(classification_report(labels_test, predictions))\n",
    "print(\"ROC-AUC:\", roc_auc_score(labels_test, predictions))\n",
    "\n",
    "classifier = pipeline.named_steps['classifier']\n",
    "importances = classifier.feature_importances_\n",
    "plt.bar(range(importances.shape[0]), importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: hemingway_bell_tolls.txt\n",
      "Processing file: hemingway_sun_also.txt\n",
      "Processing file: hemingway_in_our_time.txt\n",
      "Processing file: hemingway_green_hills_africa.txt\n",
      "Processing file: hemingway_three_stories_ten_poems.txt\n",
      "Processing file: hemingway_across_the_river.txt\n",
      "Processing file: hemingway_winner_take_nothing.txt\n",
      "Processing file: hemingway_old_man.txt\n",
      "Processing file: hemingway_farewell.txt\n",
      "Processing file: hemingway_men_without_women.txt\n",
      "Processing file: fitzgerald_flappers_and_philosophers.txt\n",
      "Processing file: fitzgerald_tender_is.txt\n",
      "Processing file: fitzgerald_bablyon_revisited.txt\n",
      "Processing file: fitzgerald_gatsby.txt\n",
      "Processing file: fitzgerald_beautiful_and_damned.txt\n",
      "Processing file: fitzgerald_the_vegtable.txt\n",
      "Processing file: fitzgerald_tales_jazz_age.txt\n",
      "Processing file: fitzgerald_this_side.txt\n",
      "Processing file: fitzgerald_all_the_sad.txt\n",
      "Processing file: hemingway_bell_tolls.txt\n",
      "Processing file: hemingway_sun_also.txt\n",
      "Processing file: hemingway_in_our_time.txt\n",
      "Processing file: hemingway_green_hills_africa.txt\n",
      "Processing file: hemingway_three_stories_ten_poems.txt\n",
      "Processing file: hemingway_across_the_river.txt\n",
      "Processing file: hemingway_winner_take_nothing.txt\n",
      "Processing file: hemingway_old_man.txt\n",
      "Processing file: hemingway_farewell.txt\n",
      "Processing file: hemingway_men_without_women.txt\n",
      "Processing file: fitzgerald_flappers_and_philosophers.txt\n",
      "Processing file: fitzgerald_tender_is.txt\n",
      "Processing file: fitzgerald_bablyon_revisited.txt\n",
      "Processing file: fitzgerald_gatsby.txt\n",
      "Processing file: fitzgerald_beautiful_and_damned.txt\n",
      "Processing file: fitzgerald_the_vegtable.txt\n",
      "Processing file: fitzgerald_tales_jazz_age.txt\n",
      "Processing file: fitzgerald_this_side.txt\n",
      "Processing file: fitzgerald_all_the_sad.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from helper_functions import load_data\n",
    "import pandas as pd\n",
    "\n",
    "text_data, labels = load_data('data')\n",
    "\n",
    "df = pd.DataFrame(list(zip(text_data, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19e56c70b3071a7c9e5271d6c05d63446be4cb37f733ae995dda36f1f67e797e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
